{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from keras) (1.13.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from keras) (1.16.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from keras) (6.0.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from keras) (1.1.2)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.2)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Collecting keras>=3.0.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Using cached keras-3.2.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
      "Using cached keras-3.2.1-py3-none-any.whl (1.1 MB)\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.2.5\n",
      "    Uninstalling Keras-2.2.5:\n",
      "      Successfully uninstalled Keras-2.2.5\n",
      "Successfully installed keras-3.2.1\n",
      "Requirement already satisfied: numpy in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sumit\\anaconda3\\envs\\lpv_imdb\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras \n",
    "!pip install tensorflow\n",
    "!pip install numpy\n",
    "!pip install pandas \n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data, keeping only 10,000 of the most frequently occuring words\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1,\n",
       "  14,\n",
       "  22,\n",
       "  16,\n",
       "  43,\n",
       "  530,\n",
       "  973,\n",
       "  1622,\n",
       "  1385,\n",
       "  65,\n",
       "  458,\n",
       "  4468,\n",
       "  66,\n",
       "  3941,\n",
       "  4,\n",
       "  173,\n",
       "  36,\n",
       "  256,\n",
       "  5,\n",
       "  25,\n",
       "  100,\n",
       "  43,\n",
       "  838,\n",
       "  112,\n",
       "  50,\n",
       "  670,\n",
       "  2,\n",
       "  9,\n",
       "  35,\n",
       "  480,\n",
       "  284,\n",
       "  5,\n",
       "  150,\n",
       "  4,\n",
       "  172,\n",
       "  112,\n",
       "  167,\n",
       "  2,\n",
       "  336,\n",
       "  385,\n",
       "  39,\n",
       "  4,\n",
       "  172,\n",
       "  4536,\n",
       "  1111,\n",
       "  17,\n",
       "  546,\n",
       "  38,\n",
       "  13,\n",
       "  447,\n",
       "  4,\n",
       "  192,\n",
       "  50,\n",
       "  16,\n",
       "  6,\n",
       "  147,\n",
       "  2025,\n",
       "  19,\n",
       "  14,\n",
       "  22,\n",
       "  4,\n",
       "  1920,\n",
       "  4613,\n",
       "  469,\n",
       "  4,\n",
       "  22,\n",
       "  71,\n",
       "  87,\n",
       "  12,\n",
       "  16,\n",
       "  43,\n",
       "  530,\n",
       "  38,\n",
       "  76,\n",
       "  15,\n",
       "  13,\n",
       "  1247,\n",
       "  4,\n",
       "  22,\n",
       "  17,\n",
       "  515,\n",
       "  17,\n",
       "  12,\n",
       "  16,\n",
       "  626,\n",
       "  18,\n",
       "  2,\n",
       "  5,\n",
       "  62,\n",
       "  386,\n",
       "  12,\n",
       "  8,\n",
       "  316,\n",
       "  8,\n",
       "  106,\n",
       "  5,\n",
       "  4,\n",
       "  2223,\n",
       "  5244,\n",
       "  16,\n",
       "  480,\n",
       "  66,\n",
       "  3785,\n",
       "  33,\n",
       "  4,\n",
       "  130,\n",
       "  12,\n",
       "  16,\n",
       "  38,\n",
       "  619,\n",
       "  5,\n",
       "  25,\n",
       "  124,\n",
       "  51,\n",
       "  36,\n",
       "  135,\n",
       "  48,\n",
       "  25,\n",
       "  1415,\n",
       "  33,\n",
       "  6,\n",
       "  22,\n",
       "  12,\n",
       "  215,\n",
       "  28,\n",
       "  77,\n",
       "  52,\n",
       "  5,\n",
       "  14,\n",
       "  407,\n",
       "  16,\n",
       "  82,\n",
       "  2,\n",
       "  8,\n",
       "  4,\n",
       "  107,\n",
       "  117,\n",
       "  5952,\n",
       "  15,\n",
       "  256,\n",
       "  4,\n",
       "  2,\n",
       "  7,\n",
       "  3766,\n",
       "  5,\n",
       "  723,\n",
       "  36,\n",
       "  71,\n",
       "  43,\n",
       "  530,\n",
       "  476,\n",
       "  26,\n",
       "  400,\n",
       "  317,\n",
       "  46,\n",
       "  7,\n",
       "  4,\n",
       "  2,\n",
       "  1029,\n",
       "  13,\n",
       "  104,\n",
       "  88,\n",
       "  4,\n",
       "  381,\n",
       "  15,\n",
       "  297,\n",
       "  98,\n",
       "  32,\n",
       "  2071,\n",
       "  56,\n",
       "  26,\n",
       "  141,\n",
       "  6,\n",
       "  194,\n",
       "  7486,\n",
       "  18,\n",
       "  4,\n",
       "  226,\n",
       "  22,\n",
       "  21,\n",
       "  134,\n",
       "  476,\n",
       "  26,\n",
       "  480,\n",
       "  5,\n",
       "  144,\n",
       "  30,\n",
       "  5535,\n",
       "  18,\n",
       "  51,\n",
       "  36,\n",
       "  28,\n",
       "  224,\n",
       "  92,\n",
       "  25,\n",
       "  104,\n",
       "  4,\n",
       "  226,\n",
       "  65,\n",
       "  16,\n",
       "  38,\n",
       "  1334,\n",
       "  88,\n",
       "  12,\n",
       "  16,\n",
       "  283,\n",
       "  5,\n",
       "  16,\n",
       "  4472,\n",
       "  113,\n",
       "  103,\n",
       "  32,\n",
       "  15,\n",
       "  16,\n",
       "  5345,\n",
       "  19,\n",
       "  178,\n",
       "  32],\n",
       " [1,\n",
       "  194,\n",
       "  1153,\n",
       "  194,\n",
       "  8255,\n",
       "  78,\n",
       "  228,\n",
       "  5,\n",
       "  6,\n",
       "  1463,\n",
       "  4369,\n",
       "  5012,\n",
       "  134,\n",
       "  26,\n",
       "  4,\n",
       "  715,\n",
       "  8,\n",
       "  118,\n",
       "  1634,\n",
       "  14,\n",
       "  394,\n",
       "  20,\n",
       "  13,\n",
       "  119,\n",
       "  954,\n",
       "  189,\n",
       "  102,\n",
       "  5,\n",
       "  207,\n",
       "  110,\n",
       "  3103,\n",
       "  21,\n",
       "  14,\n",
       "  69,\n",
       "  188,\n",
       "  8,\n",
       "  30,\n",
       "  23,\n",
       "  7,\n",
       "  4,\n",
       "  249,\n",
       "  126,\n",
       "  93,\n",
       "  4,\n",
       "  114,\n",
       "  9,\n",
       "  2300,\n",
       "  1523,\n",
       "  5,\n",
       "  647,\n",
       "  4,\n",
       "  116,\n",
       "  9,\n",
       "  35,\n",
       "  8163,\n",
       "  4,\n",
       "  229,\n",
       "  9,\n",
       "  340,\n",
       "  1322,\n",
       "  4,\n",
       "  118,\n",
       "  9,\n",
       "  4,\n",
       "  130,\n",
       "  4901,\n",
       "  19,\n",
       "  4,\n",
       "  1002,\n",
       "  5,\n",
       "  89,\n",
       "  29,\n",
       "  952,\n",
       "  46,\n",
       "  37,\n",
       "  4,\n",
       "  455,\n",
       "  9,\n",
       "  45,\n",
       "  43,\n",
       "  38,\n",
       "  1543,\n",
       "  1905,\n",
       "  398,\n",
       "  4,\n",
       "  1649,\n",
       "  26,\n",
       "  6853,\n",
       "  5,\n",
       "  163,\n",
       "  11,\n",
       "  3215,\n",
       "  2,\n",
       "  4,\n",
       "  1153,\n",
       "  9,\n",
       "  194,\n",
       "  775,\n",
       "  7,\n",
       "  8255,\n",
       "  2,\n",
       "  349,\n",
       "  2637,\n",
       "  148,\n",
       "  605,\n",
       "  2,\n",
       "  8003,\n",
       "  15,\n",
       "  123,\n",
       "  125,\n",
       "  68,\n",
       "  2,\n",
       "  6853,\n",
       "  15,\n",
       "  349,\n",
       "  165,\n",
       "  4362,\n",
       "  98,\n",
       "  5,\n",
       "  4,\n",
       "  228,\n",
       "  9,\n",
       "  43,\n",
       "  2,\n",
       "  1157,\n",
       "  15,\n",
       "  299,\n",
       "  120,\n",
       "  5,\n",
       "  120,\n",
       "  174,\n",
       "  11,\n",
       "  220,\n",
       "  175,\n",
       "  136,\n",
       "  50,\n",
       "  9,\n",
       "  4373,\n",
       "  228,\n",
       "  8255,\n",
       "  5,\n",
       "  2,\n",
       "  656,\n",
       "  245,\n",
       "  2350,\n",
       "  5,\n",
       "  4,\n",
       "  9837,\n",
       "  131,\n",
       "  152,\n",
       "  491,\n",
       "  18,\n",
       "  2,\n",
       "  32,\n",
       "  7464,\n",
       "  1212,\n",
       "  14,\n",
       "  9,\n",
       "  6,\n",
       "  371,\n",
       "  78,\n",
       "  22,\n",
       "  625,\n",
       "  64,\n",
       "  1382,\n",
       "  9,\n",
       "  8,\n",
       "  168,\n",
       "  145,\n",
       "  23,\n",
       "  4,\n",
       "  1690,\n",
       "  15,\n",
       "  16,\n",
       "  4,\n",
       "  1355,\n",
       "  5,\n",
       "  28,\n",
       "  6,\n",
       "  52,\n",
       "  154,\n",
       "  462,\n",
       "  33,\n",
       "  89,\n",
       "  78,\n",
       "  285,\n",
       "  16,\n",
       "  145,\n",
       "  95]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first label\n",
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since we restricted ourselves to the top 10000 frequent words, no word index should exceed 10000\n",
    "# we'll verify this below\n",
    "\n",
    "# Here is a list of maximum indexes in every review --- we search the maximum index in this list of max indexes\n",
    "print(type([max(sequence) for sequence in train_data]))\n",
    "\n",
    "# Find the maximum of all max indexes\n",
    "max([max(sequence) for sequence in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's quickly decode a review\n",
    "\n",
    "# step 1: load the dictionary mappings from word to integer index\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "# step 2: reverse word index to map integer indexes to their respective words\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "# Step 3: decode the review, mapping integer indices to words\n",
    "#\n",
    "# indices are off by 3 because 0, 1, and 2 are reserverd indices for \"padding\", \"Start of sequence\" and \"unknown\"\n",
    "decoded_review = ' '.join([reverse_word_index.get(i-3, '?') for i in train_data[0]])\n",
    "\n",
    "decoded_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88584"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reverse_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))    # Creates an all zero matrix of shape (len(sequences),10K)\n",
    "    for i,sequence in enumerate(sequences):\n",
    "        results[i,sequence] = 1                        # Sets specific indices of results[i] to 1s\n",
    "    return results\n",
    "\n",
    "# Vectorize training Data\n",
    "X_train = vectorize_sequences(train_data)\n",
    "\n",
    "# Vectorize testing Data\n",
    "X_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 10000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test  = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sumit\\anaconda3\\envs\\lpv_imdb\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizers.RMSprop(learning_rate=0.001),\n",
    "    loss = losses.binary_crossentropy,\n",
    "    metrics = [metrics.binary_accuracy]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input for Validation\n",
    "X_val = X_train[:10000]\n",
    "partial_X_train = X_train[10000:]\n",
    "\n",
    "# Labels for validation\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - binary_accuracy: 0.6964 - loss: 0.5804 - val_binary_accuracy: 0.8666 - val_loss: 0.3743\n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9051 - loss: 0.3108 - val_binary_accuracy: 0.8834 - val_loss: 0.3051\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 0.9244 - loss: 0.2343 - val_binary_accuracy: 0.8893 - val_loss: 0.2814\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - binary_accuracy: 0.9450 - loss: 0.1831 - val_binary_accuracy: 0.8883 - val_loss: 0.2799\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9575 - loss: 0.1444 - val_binary_accuracy: 0.8829 - val_loss: 0.2875\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - binary_accuracy: 0.9648 - loss: 0.1229 - val_binary_accuracy: 0.8754 - val_loss: 0.3282\n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9694 - loss: 0.1086 - val_binary_accuracy: 0.8783 - val_loss: 0.3154\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - binary_accuracy: 0.9781 - loss: 0.0877 - val_binary_accuracy: 0.8770 - val_loss: 0.3343\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9796 - loss: 0.0800 - val_binary_accuracy: 0.8775 - val_loss: 0.3461\n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9828 - loss: 0.0660 - val_binary_accuracy: 0.8816 - val_loss: 0.3567\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9859 - loss: 0.0561 - val_binary_accuracy: 0.8802 - val_loss: 0.3723\n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9892 - loss: 0.0475 - val_binary_accuracy: 0.8695 - val_loss: 0.4118\n",
      "Epoch 13/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9918 - loss: 0.0398 - val_binary_accuracy: 0.8677 - val_loss: 0.4340\n",
      "Epoch 14/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.9936 - loss: 0.0332 - val_binary_accuracy: 0.8700 - val_loss: 0.4477\n",
      "Epoch 15/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9959 - loss: 0.0289 - val_binary_accuracy: 0.8699 - val_loss: 0.4744\n",
      "Epoch 16/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - binary_accuracy: 0.9966 - loss: 0.0280 - val_binary_accuracy: 0.8713 - val_loss: 0.4894\n",
      "Epoch 17/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - binary_accuracy: 0.9970 - loss: 0.0207 - val_binary_accuracy: 0.8709 - val_loss: 0.5044\n",
      "Epoch 18/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - binary_accuracy: 0.9990 - loss: 0.0155 - val_binary_accuracy: 0.8691 - val_loss: 0.5361\n",
      "Epoch 19/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - binary_accuracy: 0.9987 - loss: 0.0140 - val_binary_accuracy: 0.8685 - val_loss: 0.5559\n",
      "Epoch 20/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - binary_accuracy: 0.9994 - loss: 0.0123 - val_binary_accuracy: 0.8691 - val_loss: 0.5769\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    partial_X_train,\n",
    "    partial_y_train,\n",
    "    epochs=20,\n",
    "    batch_size=512,\n",
    "    validation_data=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_token(tid):\n",
    "    for k,v in word_index.items():\n",
    "        # We decode the review; note that our indices were offset by 3\n",
    "        # because 0, 1 and 2 are reserved indices for \"padding\", \"start of sequence\", and \"unknown\".\n",
    "        if v==tid-3:\n",
    "            return k\n",
    "    return '?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_review(id_):\n",
    "    sentence = ' '.join(return_token(i) for i in train_data[id_])\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_review(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_label[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_label' is not defined"
     ]
    }
   ],
   "source": [
    "train_label[0] #Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_review(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label[1] # Negaive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_review(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[2] # Negaive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
